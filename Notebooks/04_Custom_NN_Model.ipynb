{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cea2ee5",
   "metadata": {},
   "source": [
    "# Custom Neural Network Design for Early Sepsis Prediction\n",
    "\n",
    "This notebook formalizes the architecture, training strategy, and evaluation framework \n",
    "for predicting sepsis onset 2h, 4h, and 6h in advance using time-series laboratory data.\n",
    "\n",
    "We explicitly define:\n",
    "- Input tensor structure\n",
    "- Model architecture\n",
    "- Initialization strategy\n",
    "- Training strategy\n",
    "- Evaluation metrics\n",
    "- Justification grounded in course concepts\n",
    "\n",
    "Three separate models will be trained for 2h, 4h, and 6h horizons to ensure \n",
    "clarity, interpretability, and clean feature importance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80d547",
   "metadata": {},
   "source": [
    "## STAGE ALIGNMENT\n",
    "\n",
    "Input:\n",
    "- Processed time-series dataset (Parquet)\n",
    "- Patient-level split preserved\n",
    "- Engineered labels (2h, 4h, 6h)\n",
    "\n",
    "Output:\n",
    "- Verified tensor structure\n",
    "- Confirmed class imbalance\n",
    "- Finalized architecture design\n",
    "- Locked training strategy\n",
    "\n",
    "Next Stage Dependency:\n",
    "- Implementation of LSTM-based neural network\n",
    "- Weighted training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2867c488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8cf621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Path Exists: True\n",
      "Files in Processed Folder:\n",
      "[WindowsPath('../Data/processed/.gitkeep'), WindowsPath('../Data/processed/sepsis_labeled_2h.pkl'), WindowsPath('../Data/processed/sepsis_labeled_4h.pkl'), WindowsPath('../Data/processed/sepsis_labeled_6h.pkl')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define project root relative to notebook\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "PROCESSED_PATH = PROJECT_ROOT / \"Data\" / \"processed\"\n",
    "\n",
    "print(\"Processed Path Exists:\", PROCESSED_PATH.exists())\n",
    "print(\"Files in Processed Folder:\")\n",
    "print(list(PROCESSED_PATH.iterdir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6794e029",
   "metadata": {},
   "source": [
    "## Dataset Loading — 2h Horizon\n",
    "\n",
    "We begin with the 2-hour labeled dataset to validate structural integrity before \n",
    "constructing temporal sequences. This horizon is the most imbalanced and \n",
    "clinically challenging, making it an appropriate starting point. \n",
    "\n",
    "This step verifies dataset dimensions, patient count, and feature structure \n",
    "before introducing sequence modeling complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251b49e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (602568, 48)\n",
      "Unique Patients: 1275\n",
      "Columns: 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sepsis</th>\n",
       "      <th>severity</th>\n",
       "      <th>timestep</th>\n",
       "      <th>respiratory_minute_volume</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>leukocytes</th>\n",
       "      <th>temperature</th>\n",
       "      <th>partial_co2</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>potassium</th>\n",
       "      <th>mixed_venous_oxygen_saturation</th>\n",
       "      <th>urine_output</th>\n",
       "      <th>net balance</th>\n",
       "      <th>alanine_transaminase</th>\n",
       "      <th>aspartate_transaminase</th>\n",
       "      <th>stroke_volume</th>\n",
       "      <th>svri</th>\n",
       "      <th>age</th>\n",
       "      <th>label_2h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190898</td>\n",
       "      <td>0.424464</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>-0.168117</td>\n",
       "      <td>-0.275272</td>\n",
       "      <td>1.879692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334653</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>-0.710447</td>\n",
       "      <td>1.259337</td>\n",
       "      <td>-0.023852</td>\n",
       "      <td>0.117472</td>\n",
       "      <td>0.317126</td>\n",
       "      <td>0.061715</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.157654</td>\n",
       "      <td>0.667394</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>-0.168117</td>\n",
       "      <td>-0.275272</td>\n",
       "      <td>1.708485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334653</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>-0.710447</td>\n",
       "      <td>1.259337</td>\n",
       "      <td>-0.023852</td>\n",
       "      <td>0.117472</td>\n",
       "      <td>0.317126</td>\n",
       "      <td>0.061715</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024678</td>\n",
       "      <td>0.618808</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>-0.732387</td>\n",
       "      <td>1.003408</td>\n",
       "      <td>2.050899</td>\n",
       "      <td>...</td>\n",
       "      <td>2.923028</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>-0.710447</td>\n",
       "      <td>1.259337</td>\n",
       "      <td>-0.023852</td>\n",
       "      <td>0.117472</td>\n",
       "      <td>0.317126</td>\n",
       "      <td>0.061715</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.208030</td>\n",
       "      <td>0.278706</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>-0.732387</td>\n",
       "      <td>1.003408</td>\n",
       "      <td>1.366071</td>\n",
       "      <td>...</td>\n",
       "      <td>2.923028</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>-0.710447</td>\n",
       "      <td>1.259337</td>\n",
       "      <td>-0.023852</td>\n",
       "      <td>0.117472</td>\n",
       "      <td>0.317126</td>\n",
       "      <td>0.061715</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.108298</td>\n",
       "      <td>-0.352912</td>\n",
       "      <td>0.301015</td>\n",
       "      <td>-0.732387</td>\n",
       "      <td>1.094023</td>\n",
       "      <td>1.537278</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719423</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>-0.710447</td>\n",
       "      <td>0.452120</td>\n",
       "      <td>-0.023852</td>\n",
       "      <td>0.117472</td>\n",
       "      <td>0.317126</td>\n",
       "      <td>0.061715</td>\n",
       "      <td>0.371047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  sepsis  severity  timestep  respiratory_minute_volume  heart_rate  \\\n",
       "0  12292       0       0.0       0.0                   0.190898    0.424464   \n",
       "1  12292       0       0.0       0.5                   0.157654    0.667394   \n",
       "2  12292       0       0.0       1.0                   0.024678    0.618808   \n",
       "3  12292       0       0.0       1.5                  -0.208030    0.278706   \n",
       "4  12292       0       0.0       2.0                  -0.108298   -0.352912   \n",
       "\n",
       "   leukocytes  temperature  partial_co2  respiratory_rate  ...  potassium  \\\n",
       "0    0.301015    -0.168117    -0.275272          1.879692  ...  -0.334653   \n",
       "1    0.301015    -0.168117    -0.275272          1.708485  ...  -0.334653   \n",
       "2    0.301015    -0.732387     1.003408          2.050899  ...   2.923028   \n",
       "3    0.301015    -0.732387     1.003408          1.366071  ...   2.923028   \n",
       "4    0.301015    -0.732387     1.094023          1.537278  ...   2.719423   \n",
       "\n",
       "   mixed_venous_oxygen_saturation  urine_output  net balance  \\\n",
       "0                        0.010733     -0.710447     1.259337   \n",
       "1                        0.010733     -0.710447     1.259337   \n",
       "2                        0.010733     -0.710447     1.259337   \n",
       "3                        0.010733     -0.710447     1.259337   \n",
       "4                        0.010733     -0.710447     0.452120   \n",
       "\n",
       "   alanine_transaminase  aspartate_transaminase  stroke_volume      svri  \\\n",
       "0             -0.023852                0.117472       0.317126  0.061715   \n",
       "1             -0.023852                0.117472       0.317126  0.061715   \n",
       "2             -0.023852                0.117472       0.317126  0.061715   \n",
       "3             -0.023852                0.117472       0.317126  0.061715   \n",
       "4             -0.023852                0.117472       0.317126  0.061715   \n",
       "\n",
       "        age  label_2h  \n",
       "0  0.371047         0  \n",
       "1  0.371047         0  \n",
       "2  0.371047         0  \n",
       "3  0.371047         0  \n",
       "4  0.371047         0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 2h labeled dataset\n",
    "df_2h = pd.read_pickle(PROCESSED_PATH / \"sepsis_labeled_2h.pkl\")\n",
    "\n",
    "print(\"Shape:\", df_2h.shape)\n",
    "print(\"Unique Patients:\", df_2h[\"id\"].nunique())\n",
    "print(\"Columns:\", len(df_2h.columns))\n",
    "\n",
    "df_2h.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6a548",
   "metadata": {},
   "source": [
    "### Structural Insight\n",
    "\n",
    "The dataset contains 602,568 time-indexed observations across 1,275 patients.\n",
    "Each row represents a physiological snapshot at a specific timestep.\n",
    "\n",
    "Since sepsis is a progressive condition rather than a sudden event,\n",
    "row-wise data must be transformed into temporal sequences before\n",
    "training a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5d2fea",
   "metadata": {},
   "source": [
    "## Label Distribution — 2h\n",
    "\n",
    "We verify class imbalance before sequence construction, \n",
    "as it directly affects loss design and evaluation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a93c8c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 602568\n",
      "Positive Samples: 1480\n",
      "Positive Rate: 0.0024561543261507413\n"
     ]
    }
   ],
   "source": [
    "positive_rate = df_2h[\"label_2h\"].mean()\n",
    "positive_count = df_2h[\"label_2h\"].sum()\n",
    "total_count = len(df_2h)\n",
    "\n",
    "print(\"Total Samples:\", total_count)\n",
    "print(\"Positive Samples:\", int(positive_count))\n",
    "print(\"Positive Rate:\", positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d968f68",
   "metadata": {},
   "source": [
    "## Temporal Structure Analysis\n",
    "\n",
    "Before constructing sliding windows, we verify:\n",
    "- Timestep resolution\n",
    "- Consistency of spacing\n",
    "- Number of observations per patient\n",
    "\n",
    "This ensures the chosen sequence length is structurally valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b263cd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26734     0.0\n",
       "26735     0.5\n",
       "26736     1.0\n",
       "26737     1.5\n",
       "26738     2.0\n",
       "26739     2.5\n",
       "26740     3.0\n",
       "26741     3.5\n",
       "26742     4.0\n",
       "26743     4.5\n",
       "341361    0.0\n",
       "341362    0.5\n",
       "341363    1.0\n",
       "341364    1.5\n",
       "341365    2.0\n",
       "341366    2.5\n",
       "341367    3.0\n",
       "341368    3.5\n",
       "341369    4.0\n",
       "341370    4.5\n",
       "Name: timestep, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2h.sort_values([\"id\", \"timestep\"]).groupby(\"id\")[\"timestep\"].head(10).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f4231f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestep_diff\n",
       "0.5    601293\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2h[\"timestep_diff\"] = df_2h.groupby(\"id\")[\"timestep\"].diff()\n",
    "df_2h[\"timestep_diff\"].dropna().value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2709477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min records per patient: 32\n",
      "Median records per patient: 209.0\n",
      "Max records per patient: 5424\n"
     ]
    }
   ],
   "source": [
    "records_per_patient = df_2h.groupby(\"id\").size()\n",
    "\n",
    "print(\"Min records per patient:\", records_per_patient.min())\n",
    "print(\"Median records per patient:\", records_per_patient.median())\n",
    "print(\"Max records per patient:\", records_per_patient.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416363d",
   "metadata": {},
   "source": [
    "### Temporal Structure Insight\n",
    "\n",
    "Timestep increases consistently in increments of 0.5, confirming uniform sampling.\n",
    "This means each step represents 30 minutes.\n",
    "\n",
    "All patients have at least 32 observations, with a median of 209 and a maximum of 5,424.\n",
    "Therefore, every patient has sufficient history to construct temporal windows.\n",
    "\n",
    "Given 0.5-hour resolution:\n",
    "- 12 timesteps = 6 hours of history\n",
    "- 24 timesteps = 12 hours of history\n",
    "\n",
    "This validates the feasibility of fixed-length sliding windows for sequence modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b23f87e",
   "metadata": {},
   "source": [
    "## Sequence Construction — 2h Model\n",
    "\n",
    "We construct fixed-length sliding windows of 12 timesteps (6 hours history).\n",
    "Each training sample consists of:\n",
    "\n",
    "- Input: 12 consecutive timesteps of physiological features\n",
    "- Target: label_2h at the final timestep of the window\n",
    "\n",
    "Patient boundaries are strictly preserved to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64fb37c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['timestep', 'respiratory_minute_volume', 'heart_rate', 'leukocytes',\n",
       "       'temperature', 'partial_co2', 'respiratory_rate', 'arterial_ph',\n",
       "       'bilirubin', 'blood_urea_nitrogen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = df_2h.columns.drop([\"id\", \"sepsis\", \"severity\", \"label_2h\", \"timestep_diff\"])\n",
    "print(\"Number of features:\", len(feature_cols))\n",
    "feature_cols[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a03bed",
   "metadata": {},
   "source": [
    "### Feature Structure Insight\n",
    "\n",
    "After excluding identifiers and target-related columns, 44 physiological \n",
    "features remain available for modeling.\n",
    "\n",
    "The timestep variable is retained as a feature, allowing the model to \n",
    "learn relative temporal positioning within each sequence.\n",
    "\n",
    "These 44 variables will form the feature dimension of each timestep \n",
    "within the constructed sliding windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de84df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (588543, 12, 44)\n",
      "y shape: (588543,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 12  # 12 timesteps = 6 hours history\n",
    "\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "\n",
    "for patient_id, group in df_2h.groupby(\"id\"):\n",
    "    group = group.sort_values(\"timestep\")\n",
    "    \n",
    "    features = group[feature_cols].values\n",
    "    labels = group[\"label_2h\"].values\n",
    "    \n",
    "    for i in range(len(group) - SEQUENCE_LENGTH + 1):\n",
    "        X_sequences.append(features[i:i+SEQUENCE_LENGTH])\n",
    "        y_sequences.append(labels[i+SEQUENCE_LENGTH-1])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y_sequences = np.array(y_sequences)\n",
    "\n",
    "print(\"X shape:\", X_sequences.shape)\n",
    "print(\"y shape:\", y_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05725ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 588543\n",
      "Positive Sequences: 1480\n",
      "Positive Rate (Sequence Level): 0.0025146845685022163\n"
     ]
    }
   ],
   "source": [
    "positive_rate_seq = y_sequences.mean()\n",
    "positive_count_seq = y_sequences.sum()\n",
    "\n",
    "print(\"Total Sequences:\", len(y_sequences))\n",
    "print(\"Positive Sequences:\", int(positive_count_seq))\n",
    "print(\"Positive Rate (Sequence Level):\", positive_rate_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805113d2",
   "metadata": {},
   "source": [
    "### Sequence-Level Imbalance Insight\n",
    "\n",
    "After temporal windowing, 588,543 training sequences were generated.\n",
    "\n",
    "Positive sequences: 1,480  \n",
    "Positive rate ≈ 0.251%\n",
    "\n",
    "Class imbalance remains extreme and nearly unchanged after window construction.\n",
    "\n",
    "Therefore:\n",
    "- Weighted loss is mandatory.\n",
    "- Accuracy remains misleading.\n",
    "- ROC-AUC and PR-AUC will be primary evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310eefd",
   "metadata": {},
   "source": [
    "## Patient-Level Split (2h)\n",
    "\n",
    "We split patients before sequence construction to prevent temporal leakage \n",
    "across train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64c97a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Patients: 1020\n",
      "Test Patients: 255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "patient_ids = df_2h[\"id\"].unique()\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    patient_ids,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df = df_2h[df_2h[\"id\"].isin(train_ids)]\n",
    "test_df = df_2h[df_2h[\"id\"].isin(test_ids)]\n",
    "\n",
    "print(\"Train Patients:\", len(train_ids))\n",
    "print(\"Test Patients:\", len(test_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1a733",
   "metadata": {},
   "source": [
    "### Split Insight\n",
    "\n",
    "1,020 patients in training and 255 in testing.\n",
    "The split is performed at the patient level, ensuring no temporal leakage\n",
    "between training and evaluation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad07850",
   "metadata": {},
   "source": [
    "## Sequence Construction — Train & Test\n",
    "Sliding windows are constructed independently for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d75ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (471469, 12, 44)\n",
      "Test shape: (117074, 12, 44)\n"
     ]
    }
   ],
   "source": [
    "def build_sequences(df, feature_cols, label_col, seq_len=12):\n",
    "    X_seq, y_seq = [], []\n",
    "    \n",
    "    for pid, group in df.groupby(\"id\"):\n",
    "        group = group.sort_values(\"timestep\")\n",
    "        features = group[feature_cols].values\n",
    "        labels = group[label_col].values\n",
    "        \n",
    "        for i in range(len(group) - seq_len + 1):\n",
    "            X_seq.append(features[i:i+seq_len])\n",
    "            y_seq.append(labels[i+seq_len-1])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "\n",
    "X_train, y_train = build_sequences(train_df, feature_cols, \"label_2h\")\n",
    "X_test, y_test = build_sequences(test_df, feature_cols, \"label_2h\")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55499f53",
   "metadata": {},
   "source": [
    "### Sequence Split Insight\n",
    "\n",
    "471,469 training sequences and 117,074 testing sequences were generated.\n",
    "Train and test tensors are fully separated at the patient level,\n",
    "eliminating temporal and subject leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475318b3",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "We standardize features using training data statistics only,\n",
    "then apply the same transformation to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b61e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled train shape: (471469, 12, 44)\n",
      "Scaled test shape: (117074, 12, 44)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# reshape for scaling (combine sequence dimension temporarily)\n",
    "num_train, seq_len, num_features = X_train.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_reshaped = X_train.reshape(-1, num_features)\n",
    "X_test_reshaped = X_test.reshape(-1, num_features)\n",
    "\n",
    "# Fit only on training\n",
    "scaler.fit(X_train_reshaped)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_reshaped).reshape(num_train, seq_len, num_features)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape[0], seq_len, num_features)\n",
    "\n",
    "print(\"Scaled train shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled test shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c9f006",
   "metadata": {},
   "source": [
    "### Scaling Insight\n",
    "\n",
    "Features were standardized using training data statistics only.\n",
    "Tensor structure (12, 44) was preserved after reshaping.\n",
    "\n",
    "The model will now receive numerically stable inputs,\n",
    "which is essential for effective gradient-based learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df54e2b",
   "metadata": {},
   "source": [
    "## PyTorch Tensor Conversion\n",
    "\n",
    "Convert scaled NumPy arrays into PyTorch tensors \n",
    "for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac2019ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensor shape: torch.Size([471469, 12, 44])\n",
      "Test tensor shape: torch.Size([117074, 12, 44])\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "print(\"Train tensor shape:\", X_train_tensor.shape)\n",
    "print(\"Test tensor shape:\", X_test_tensor.shape)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef7d33",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader\n",
    "\n",
    "Create PyTorch Dataset and DataLoader for mini-batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62fa76d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1842\n",
      "Test batches: 458\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SepsisDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataset = SepsisDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = SepsisDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4d9a0",
   "metadata": {},
   "source": [
    "## LSTM Model Definition (2h)\n",
    "Single-layer LSTM followed by dense layers for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a2ff83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SepsisLSTM(nn.Module):\n",
    "    def __init__(self, input_size=44, hidden_size=64, dropout=0.3):\n",
    "        super(SepsisLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if \"weight_ih\" in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "            elif \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]   # Last timestep\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe48a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepsisLSTM(\n",
      "  (lstm): LSTM(44, 64, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SepsisLSTM().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a46cf",
   "metadata": {},
   "source": [
    "### Architecture Rationale\n",
    "\n",
    "- **LSTM (64 units):** Chosen to model temporal dependencies in physiological progression. \n",
    "  64 units balance expressive capacity and overfitting risk given ~588k sequences.\n",
    "\n",
    "- **Dropout (0.3):** Regularization to reduce variance due to extreme class imbalance \n",
    "  and long patient trajectories.\n",
    "\n",
    "- **Dense (32 units, ReLU):** Introduces non-linearity after temporal encoding \n",
    "  while keeping parameter count controlled.\n",
    "\n",
    "- **Sigmoid Output (1 unit):** Binary probability prediction for sepsis onset.\n",
    "\n",
    "Initialization:\n",
    "- Xavier for input weights → stable gradient flow.\n",
    "- Orthogonal for recurrent weights → preserves long-term memory dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3b600",
   "metadata": {},
   "source": [
    "## Weighted Loss Definition\n",
    "\n",
    "Due to extreme class imbalance (~0.25% positives), \n",
    "we apply class weighting in the loss function.\n",
    "\n",
    "Positive weight is computed from the training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27bba448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples (train): 1190\n",
      "Negative samples (train): 470279\n",
      "Computed pos_weight: 395.1924369747899\n"
     ]
    }
   ],
   "source": [
    "# Compute positive class weight from training sequences\n",
    "pos_count = y_train.sum()\n",
    "neg_count = len(y_train) - pos_count\n",
    "\n",
    "pos_weight_value = neg_count / pos_count\n",
    "\n",
    "print(\"Positive samples (train):\", int(pos_count))\n",
    "print(\"Negative samples (train):\", int(neg_count))\n",
    "print(\"Computed pos_weight:\", pos_weight_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8f473a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "pos_weight = torch.tensor(pos_weight_value, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16142d",
   "metadata": {},
   "source": [
    "## Training Strategy — 2h Model\n",
    "\n",
    "- Optimizer: Adam (lr=1e-3)\n",
    "- Loss: Weighted BCEWithLogitsLoss\n",
    "- Batch size: 256\n",
    "- Max epochs: 20\n",
    "- Early stopping based on validation ROC-AUC (patience = 5)\n",
    "\n",
    "Validation ROC-AUC is used as the primary selection metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7fe3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.9409 | Val ROC-AUC: 0.7698\n",
      "Epoch 2/20 | Train Loss: 0.5403 | Val ROC-AUC: 0.7722\n",
      "Epoch 3/20 | Train Loss: 0.3215 | Val ROC-AUC: 0.7513\n",
      "Epoch 4/20 | Train Loss: 0.2615 | Val ROC-AUC: 0.7662\n",
      "Epoch 5/20 | Train Loss: 0.2086 | Val ROC-AUC: 0.7466\n",
      "Epoch 6/20 | Train Loss: 0.1968 | Val ROC-AUC: 0.7533\n",
      "Epoch 7/20 | Train Loss: 0.1721 | Val ROC-AUC: 0.7525\n",
      "Early stopping triggered.\n",
      "Best Validation ROC-AUC: 0.7721574696108584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "\n",
    "EPOCHS = 20\n",
    "PATIENCE = 5\n",
    "\n",
    "best_auc = 0\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            \n",
    "            outputs = model(X_batch)\n",
    "            probs = torch.sigmoid(outputs)  # convert logits to probability\n",
    "            \n",
    "            val_preds.extend(probs.cpu().numpy())\n",
    "            val_true.extend(y_batch.numpy())\n",
    "    \n",
    "    val_auc = roc_auc_score(val_true, val_preds)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val ROC-AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    # ---- Early Stopping ----\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print(\"Best Validation ROC-AUC:\", best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcfc7f",
   "metadata": {},
   "source": [
    "## Stability Validation — 2h Model\n",
    "\n",
    "We retrain the model using different random seeds to assess \n",
    "performance stability and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2460ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def train_model_with_seed(seed):\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    model = SepsisLSTM().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    best_auc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                val_preds.extend(probs.cpu().numpy())\n",
    "                val_true.extend(y_batch.numpy())\n",
    "        \n",
    "        val_auc = roc_auc_score(val_true, val_preds)\n",
    "        \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= 5:\n",
    "            break\n",
    "    \n",
    "    return best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee106ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 | Best ROC-AUC: 0.7794\n",
      "Seed 123 | Best ROC-AUC: 0.7915\n",
      "Seed 999 | Best ROC-AUC: 0.7970\n",
      "Mean ROC-AUC: 0.7892925961751964\n",
      "Std Dev: 0.007363184572782437\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 999]\n",
    "results = []\n",
    "\n",
    "for s in seeds:\n",
    "    auc = train_model_with_seed(s)\n",
    "    print(f\"Seed {s} | Best ROC-AUC: {auc:.4f}\")\n",
    "    results.append(auc)\n",
    "\n",
    "print(\"Mean ROC-AUC:\", np.mean(results))\n",
    "print(\"Std Dev:\", np.std(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b7d78",
   "metadata": {},
   "source": [
    "### Phase 2 Summary — 2h Model\n",
    "\n",
    "The LSTM-based temporal model achieved stable performance \n",
    "(mean ROC-AUC ≈ 0.789, std ≈ 0.007), outperforming the logistic baseline.\n",
    "\n",
    "Architecture and training strategy are now frozen.\n",
    "\n",
    "To ensure scientific rigor, identical architecture and training settings \n",
    "will be applied to 4h and 6h horizons for controlled multi-horizon comparison.\n",
    "\n",
    "Optional ablation (MLP vs LSTM) may be included to evaluate \n",
    "the added value of temporal modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58615777",
   "metadata": {},
   "source": [
    "# Phase 3 — 4h Horizon Model\n",
    "\n",
    "The identical LSTM architecture and training protocol used for the 2h model \n",
    "is applied to the 4h horizon to ensure controlled comparison.\n",
    "\n",
    "Only the prediction target changes (label_4h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0d12f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (602568, 48)\n",
      "Unique Patients: 1275\n"
     ]
    }
   ],
   "source": [
    "# Load 4h dataset\n",
    "df_4h = pd.read_pickle(PROCESSED_PATH / \"sepsis_labeled_4h.pkl\")\n",
    "\n",
    "print(\"Shape:\", df_4h.shape)\n",
    "print(\"Unique Patients:\", df_4h[\"id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02e969",
   "metadata": {},
   "source": [
    "## Patient-Level Split — 4h\n",
    "Patient-level split is repeated to prevent temporal leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b00c6465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Patients: 1020\n",
      "Test Patients: 255\n"
     ]
    }
   ],
   "source": [
    "patient_ids_4h = df_4h[\"id\"].unique()\n",
    "\n",
    "train_ids_4h, test_ids_4h = train_test_split(\n",
    "    patient_ids_4h,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df_4h = df_4h[df_4h[\"id\"].isin(train_ids_4h)]\n",
    "test_df_4h = df_4h[df_4h[\"id\"].isin(test_ids_4h)]\n",
    "\n",
    "print(\"Train Patients:\", len(train_ids_4h))\n",
    "print(\"Test Patients:\", len(test_ids_4h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequence Construction — 4h\n",
    "12-step sliding windows constructed identically to 2h model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03999a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (471469, 12, 44)\n",
      "Test shape: (117074, 12, 44)\n"
     ]
    }
   ],
   "source": [
    "X_train_4h, y_train_4h = build_sequences(train_df_4h, feature_cols, \"label_4h\")\n",
    "X_test_4h, y_test_4h = build_sequences(test_df_4h, feature_cols, \"label_4h\")\n",
    "\n",
    "print(\"Train shape:\", X_train_4h.shape)\n",
    "print(\"Test shape:\", X_test_4h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a10679",
   "metadata": {},
   "source": [
    "## Label Distribution — 4h\n",
    "Verify sequence-level class imbalance before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dd6baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: 471469\n",
      "Positive sequences (train): 2142\n",
      "Positive rate (train): 0.004543246745809374\n"
     ]
    }
   ],
   "source": [
    "positive_rate_4h = y_train_4h.mean()\n",
    "positive_count_4h = y_train_4h.sum()\n",
    "\n",
    "print(\"Train sequences:\", len(y_train_4h))\n",
    "print(\"Positive sequences (train):\", int(positive_count_4h))\n",
    "print(\"Positive rate (train):\", positive_rate_4h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138bcf4",
   "metadata": {},
   "source": [
    "### Class Weight Adjustment — 4h\n",
    "\n",
    "The 4h horizon exhibits a different positive rate compared to 2h.\n",
    "Therefore, class weighting must be recomputed using the 4h training set\n",
    "to maintain imbalance-aware training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5d015ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed pos_weight (4h): 219.10690943043883\n"
     ]
    }
   ],
   "source": [
    "neg_count_4h = len(y_train_4h) - positive_count_4h\n",
    "pos_weight_4h = neg_count_4h / positive_count_4h\n",
    "\n",
    "print(\"Computed pos_weight (4h):\", pos_weight_4h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10314d7e",
   "metadata": {},
   "source": [
    "### 4h Imbalance Insight\n",
    "\n",
    "The computed positive class weight (~219) is substantially lower \n",
    "than in the 2h model (~395), reflecting reduced imbalance.\n",
    "\n",
    "This suggests that 4h prediction may provide a more learnable signal \n",
    "due to increased positive representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ff80d",
   "metadata": {},
   "source": [
    "## Feature Scaling — 4h\n",
    "Standardization performed using 4h training data statistics only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6bec217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled train shape: (471469, 12, 44)\n",
      "Scaled test shape: (117074, 12, 44)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_train_4h, seq_len, num_features = X_train_4h.shape\n",
    "\n",
    "scaler_4h = StandardScaler()\n",
    "\n",
    "X_train_reshaped_4h = X_train_4h.reshape(-1, num_features)\n",
    "X_test_reshaped_4h = X_test_4h.reshape(-1, num_features)\n",
    "\n",
    "scaler_4h.fit(X_train_reshaped_4h)\n",
    "\n",
    "X_train_scaled_4h = scaler_4h.transform(X_train_reshaped_4h)\\\n",
    "    .reshape(num_train_4h, seq_len, num_features)\n",
    "\n",
    "X_test_scaled_4h = scaler_4h.transform(X_test_reshaped_4h)\\\n",
    "    .reshape(X_test_4h.shape[0], seq_len, num_features)\n",
    "\n",
    "print(\"Scaled train shape:\", X_train_scaled_4h.shape)\n",
    "print(\"Scaled test shape:\", X_test_scaled_4h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95109a26",
   "metadata": {},
   "source": [
    "## Tensor Conversion — 4h\n",
    "Convert scaled arrays to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39647b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensor shape: torch.Size([471469, 12, 44])\n",
      "Test tensor shape: torch.Size([117074, 12, 44])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor_4h = torch.tensor(X_train_scaled_4h, dtype=torch.float32)\n",
    "y_train_tensor_4h = torch.tensor(y_train_4h, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor_4h = torch.tensor(X_test_scaled_4h, dtype=torch.float32)\n",
    "y_test_tensor_4h = torch.tensor(y_test_4h, dtype=torch.float32)\n",
    "\n",
    "print(\"Train tensor shape:\", X_train_tensor_4h.shape)\n",
    "print(\"Test tensor shape:\", X_test_tensor_4h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d22ed",
   "metadata": {},
   "source": [
    "## DataLoader — 4h\n",
    "Create mini-batch loaders identical to 2h configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cde55c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1842\n",
      "Test batches: 458\n"
     ]
    }
   ],
   "source": [
    "train_dataset_4h = SepsisDataset(X_train_tensor_4h, y_train_tensor_4h)\n",
    "test_dataset_4h = SepsisDataset(X_test_tensor_4h, y_test_tensor_4h)\n",
    "\n",
    "train_loader_4h = DataLoader(train_dataset_4h, batch_size=256, shuffle=True)\n",
    "test_loader_4h = DataLoader(test_dataset_4h, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader_4h))\n",
    "print(\"Test batches:\", len(test_loader_4h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d29b7",
   "metadata": {},
   "source": [
    "## Training — 4h Model\n",
    "Same architecture and training protocol as 2h.\n",
    "Only class weight differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1d15685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_tensor_4h = torch.tensor(pos_weight_4h, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion_4h = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor_4h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d89ffd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_seed(seed, train_loader, test_loader, criterion):\n",
    "    \n",
    "    set_seed(seed)\n",
    "    \n",
    "    model = SepsisLSTM().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    best_auc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(20):\n",
    "        \n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device).unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                val_preds.extend(probs.cpu().numpy())\n",
    "                val_true.extend(y_batch.numpy())\n",
    "        \n",
    "        val_auc = roc_auc_score(val_true, val_preds)\n",
    "        \n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= 5:\n",
    "            break\n",
    "    \n",
    "    return best_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88cb1e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 | Best ROC-AUC: 0.7769\n",
      "Seed 123 | Best ROC-AUC: 0.7734\n",
      "Seed 999 | Best ROC-AUC: 0.7841\n",
      "Mean ROC-AUC (4h): 0.7781176684920403\n",
      "Std Dev (4h): 0.004438836413767385\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 999]\n",
    "results_4h = []\n",
    "\n",
    "for s in seeds:\n",
    "    auc = train_with_seed(s, train_loader_4h, test_loader_4h, criterion_4h)\n",
    "    print(f\"Seed {s} | Best ROC-AUC: {auc:.4f}\")\n",
    "    results_4h.append(auc)\n",
    "\n",
    "print(\"Mean ROC-AUC (4h):\", np.mean(results_4h))\n",
    "print(\"Std Dev (4h):\", np.std(results_4h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff76328",
   "metadata": {},
   "source": [
    "# Phase 3 — 6h Horizon Model\n",
    "\n",
    "The identical architecture and training protocol is applied \n",
    "to the 6h prediction horizon for controlled comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf638d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (602568, 48)\n",
      "Unique Patients: 1275\n"
     ]
    }
   ],
   "source": [
    "df_6h = pd.read_pickle(PROCESSED_PATH / \"sepsis_labeled_6h.pkl\")\n",
    "\n",
    "print(\"Shape:\", df_6h.shape)\n",
    "print(\"Unique Patients:\", df_6h[\"id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e4afe",
   "metadata": {},
   "source": [
    "## Patient-Level Split — 6h\n",
    "Split patients before windowing to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16316640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Patients: 1020\n",
      "Test Patients: 255\n"
     ]
    }
   ],
   "source": [
    "patient_ids_6h = df_6h[\"id\"].unique()\n",
    "\n",
    "train_ids_6h, test_ids_6h = train_test_split(\n",
    "    patient_ids_6h,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df_6h = df_6h[df_6h[\"id\"].isin(train_ids_6h)]\n",
    "test_df_6h = df_6h[df_6h[\"id\"].isin(test_ids_6h)]\n",
    "\n",
    "print(\"Train Patients:\", len(train_ids_6h))\n",
    "print(\"Test Patients:\", len(test_ids_6h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4263e",
   "metadata": {},
   "source": [
    "## Sequence Construction — 6h\n",
    "12-step sliding windows constructed identically to previous horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89b5bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (471469, 12, 44)\n",
      "Test shape: (117074, 12, 44)\n"
     ]
    }
   ],
   "source": [
    "X_train_6h, y_train_6h = build_sequences(train_df_6h, feature_cols, \"label_6h\")\n",
    "X_test_6h, y_test_6h = build_sequences(test_df_6h, feature_cols, \"label_6h\")\n",
    "\n",
    "print(\"Train shape:\", X_train_6h.shape)\n",
    "print(\"Test shape:\", X_test_6h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05085fcc",
   "metadata": {},
   "source": [
    "## Label Distribution — 6h\n",
    "Verify sequence-level imbalance before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb48f40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: 471469\n",
      "Positive sequences (train): 3094\n",
      "Positive rate (train): 0.006562467521724652\n"
     ]
    }
   ],
   "source": [
    "positive_rate_6h = y_train_6h.mean()\n",
    "positive_count_6h = y_train_6h.sum()\n",
    "\n",
    "print(\"Train sequences:\", len(y_train_6h))\n",
    "print(\"Positive sequences (train):\", int(positive_count_6h))\n",
    "print(\"Positive rate (train):\", positive_rate_6h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e28af87",
   "metadata": {},
   "source": [
    "### Class Weight Adjustment — 6h\n",
    "Recompute class weight using 6h training distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b4d3029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed pos_weight (6h): 151.38170652876536\n"
     ]
    }
   ],
   "source": [
    "neg_count_6h = len(y_train_6h) - positive_count_6h\n",
    "pos_weight_6h = neg_count_6h / positive_count_6h\n",
    "\n",
    "print(\"Computed pos_weight (6h):\", pos_weight_6h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14ab17",
   "metadata": {},
   "source": [
    "### 6h Imbalance Insight\n",
    "\n",
    "The 6h horizon exhibits the lowest imbalance among the three tasks \n",
    "(pos_weight ≈ 151), indicating a higher proportion of positive windows.\n",
    "\n",
    "This suggests the 6h prediction task may be statistically easier \n",
    "due to increased positive representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fd099",
   "metadata": {},
   "source": [
    "## Feature Scaling — 6h\n",
    "Standardization performed using 6h training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "514fe81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled train shape: (471469, 12, 44)\n",
      "Scaled test shape: (117074, 12, 44)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_train_6h, seq_len, num_features = X_train_6h.shape\n",
    "\n",
    "scaler_6h = StandardScaler()\n",
    "\n",
    "X_train_reshaped_6h = X_train_6h.reshape(-1, num_features)\n",
    "X_test_reshaped_6h = X_test_6h.reshape(-1, num_features)\n",
    "\n",
    "# Fit only on training data\n",
    "scaler_6h.fit(X_train_reshaped_6h)\n",
    "\n",
    "X_train_scaled_6h = scaler_6h.transform(X_train_reshaped_6h)\\\n",
    "    .reshape(num_train_6h, seq_len, num_features)\n",
    "\n",
    "X_test_scaled_6h = scaler_6h.transform(X_test_reshaped_6h)\\\n",
    "    .reshape(X_test_6h.shape[0], seq_len, num_features)\n",
    "\n",
    "print(\"Scaled train shape:\", X_train_scaled_6h.shape)\n",
    "print(\"Scaled test shape:\", X_test_scaled_6h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f53a672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train tensor shape: torch.Size([471469, 12, 44])\n",
      "Test tensor shape: torch.Size([117074, 12, 44])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor_6h = torch.tensor(X_train_scaled_6h, dtype=torch.float32)\n",
    "y_train_tensor_6h = torch.tensor(y_train_6h, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor_6h = torch.tensor(X_test_scaled_6h, dtype=torch.float32)\n",
    "y_test_tensor_6h = torch.tensor(y_test_6h, dtype=torch.float32)\n",
    "\n",
    "print(\"Train tensor shape:\", X_train_tensor_6h.shape)\n",
    "print(\"Test tensor shape:\", X_test_tensor_6h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fea48a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 1842\n",
      "Test batches: 458\n"
     ]
    }
   ],
   "source": [
    "train_dataset_6h = SepsisDataset(X_train_tensor_6h, y_train_tensor_6h)\n",
    "test_dataset_6h = SepsisDataset(X_test_tensor_6h, y_test_tensor_6h)\n",
    "\n",
    "train_loader_6h = DataLoader(train_dataset_6h, batch_size=256, shuffle=True)\n",
    "test_loader_6h = DataLoader(test_dataset_6h, batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader_6h))\n",
    "print(\"Test batches:\", len(test_loader_6h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaf0c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_tensor_6h = torch.tensor(pos_weight_6h, dtype=torch.float32).to(device)\n",
    "\n",
    "criterion_6h = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor_6h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "426bf3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 | Best ROC-AUC: 0.7513\n",
      "Seed 123 | Best ROC-AUC: 0.7627\n",
      "Seed 999 | Best ROC-AUC: 0.7655\n",
      "Mean ROC-AUC (6h): 0.7598204824916661\n",
      "Std Dev (6h): 0.006102459309744642\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 123, 999]\n",
    "results_6h = []\n",
    "\n",
    "for s in seeds:\n",
    "    auc = train_with_seed(s, train_loader_6h, test_loader_6h, criterion_6h)\n",
    "    print(f\"Seed {s} | Best ROC-AUC: {auc:.4f}\")\n",
    "    results_6h.append(auc)\n",
    "\n",
    "print(\"Mean ROC-AUC (6h):\", np.mean(results_6h))\n",
    "print(\"Std Dev (6h):\", np.std(results_6h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "365ef1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Horizon</th>\n",
       "      <th>Mean ROC-AUC</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2h</td>\n",
       "      <td>0.789293</td>\n",
       "      <td>0.007363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4h</td>\n",
       "      <td>0.778118</td>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6h</td>\n",
       "      <td>0.759820</td>\n",
       "      <td>0.006102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Horizon  Mean ROC-AUC   Std Dev\n",
       "0      2h      0.789293  0.007363\n",
       "1      4h      0.778118  0.004439\n",
       "2      6h      0.759820  0.006102"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results_summary = pd.DataFrame({\n",
    "    \"Horizon\": [\"2h\", \"4h\", \"6h\"],\n",
    "    \"Mean ROC-AUC\": [\n",
    "        np.mean(results),       # 2h\n",
    "        np.mean(results_4h),    # 4h\n",
    "        np.mean(results_6h)     # 6h\n",
    "    ],\n",
    "    \"Std Dev\": [\n",
    "        np.std(results),\n",
    "        np.std(results_4h),\n",
    "        np.std(results_6h)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7064f350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(results_summary[\"Horizon\"], results_summary[\"Mean ROC-AUC\"])\n",
    "plt.ylim(0.70, 0.82)\n",
    "plt.title(\"ROC-AUC Comparison Across Prediction Horizons\")\n",
    "plt.ylabel(\"Mean ROC-AUC\")\n",
    "plt.xlabel(\"Prediction Horizon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456d610",
   "metadata": {},
   "source": [
    "## Final Multi-Horizon Comparison Summary\n",
    "\n",
    "The LSTM-based temporal model demonstrates consistent performance \n",
    "across all prediction horizons.\n",
    "\n",
    "Performance trend:\n",
    "\n",
    "2h  >  4h  >  6h\n",
    "\n",
    "Mean ROC-AUC:\n",
    "- 2h ≈ 0.789\n",
    "- 4h ≈ 0.778\n",
    "- 6h ≈ 0.760\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "1. Temporal modeling improves upon logistic regression at all horizons.\n",
    "2. Predictive signal is strongest closer to sepsis onset (2h).\n",
    "3. Performance decreases as prediction horizon increases.\n",
    "4. Model stability is high across random seeds (std < 0.01).\n",
    "\n",
    "This confirms that short-term physiological deterioration patterns \n",
    "are more discriminative than earlier-stage signals.\n",
    "\n",
    "The architecture and training protocol are now validated \n",
    "and will be used for feature importance and minimal feature set analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42a36b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting processed tensors...\n",
      "\n",
      "Export complete.\n",
      "\n",
      "Saved files:\n",
      "- scaler_2h.pkl\n",
      "- scaler_4h.pkl\n",
      "- scaler_6h.pkl\n",
      "- X_test_2h.pt\n",
      "- X_test_4h.pt\n",
      "- X_test_6h.pt\n",
      "- X_train_2h.pt\n",
      "- X_train_4h.pt\n",
      "- X_train_6h.pt\n",
      "- y_test_2h.pt\n",
      "- y_test_4h.pt\n",
      "- y_test_6h.pt\n",
      "- y_train_2h.pt\n",
      "- y_train_4h.pt\n",
      "- y_train_6h.pt\n"
     ]
    }
   ],
   "source": [
    "# EXPORT PROCESSED TENSORS\n",
    "\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import joblib\n",
    "\n",
    "EXPORT_PATH = Path(\"../Results/processed_tensors\")\n",
    "EXPORT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Exporting processed tensors...\\n\")\n",
    "\n",
    "# ---------- 2H ----------\n",
    "torch.save(X_train_tensor.cpu(), EXPORT_PATH / \"X_train_2h.pt\")\n",
    "torch.save(y_train_tensor.cpu(), EXPORT_PATH / \"y_train_2h.pt\")\n",
    "torch.save(X_test_tensor.cpu(), EXPORT_PATH / \"X_test_2h.pt\")\n",
    "torch.save(y_test_tensor.cpu(), EXPORT_PATH / \"y_test_2h.pt\")\n",
    "joblib.dump(scaler, EXPORT_PATH / \"scaler_2h.pkl\")\n",
    "\n",
    "# ---------- 4H ----------\n",
    "torch.save(X_train_tensor_4h.cpu(), EXPORT_PATH / \"X_train_4h.pt\")\n",
    "torch.save(y_train_tensor_4h.cpu(), EXPORT_PATH / \"y_train_4h.pt\")\n",
    "torch.save(X_test_tensor_4h.cpu(), EXPORT_PATH / \"X_test_4h.pt\")\n",
    "torch.save(y_test_tensor_4h.cpu(), EXPORT_PATH / \"y_test_4h.pt\")\n",
    "joblib.dump(scaler_4h, EXPORT_PATH / \"scaler_4h.pkl\")\n",
    "\n",
    "# ---------- 6H ----------\n",
    "torch.save(X_train_tensor_6h.cpu(), EXPORT_PATH / \"X_train_6h.pt\")\n",
    "torch.save(y_train_tensor_6h.cpu(), EXPORT_PATH / \"y_train_6h.pt\")\n",
    "torch.save(X_test_tensor_6h.cpu(), EXPORT_PATH / \"X_test_6h.pt\")\n",
    "torch.save(y_test_tensor_6h.cpu(), EXPORT_PATH / \"y_test_6h.pt\")\n",
    "joblib.dump(scaler_6h, EXPORT_PATH / \"scaler_6h.pkl\")\n",
    "\n",
    "print(\"Export complete.\")\n",
    "print(\"\\nSaved files:\")\n",
    "for file in EXPORT_PATH.iterdir():\n",
    "    print(\"-\", file.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-ultra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
