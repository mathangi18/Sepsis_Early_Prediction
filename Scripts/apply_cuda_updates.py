import json
import torch # Just to verify imports work in this env

path = r'c:\Users\Hope\OneDrive - KTH\StudyPeriod 3\AI & ML\Assignment2\Sepsis_Early_Prediction\Notebooks\03_Baseline_Models.ipynb'

with open(path, 'r', encoding='utf-8') as f:
    nb = json.load(f)

# Update Imports (Index 1)
nb['cells'][1]['source'] = [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n"
]

# Update run_baseline (Index 15)
# Note: Replaced tabs with 4 spaces for consistency
nb['cells'][15]['source'] = [
    "# Custom PyTorch Logistic Regression\n",
    "class PyTorchLogisticRegression:\n",
    "    def __init__(self, input_dim, learning_rate=0.01, epochs=1000, device='cuda'):\n",
    "        self.input_dim = input_dim\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, X, y, class_weight=None):\n",
    "        # Convert to tensor\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(y.values, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        self.model = torch.nn.Linear(self.input_dim, 1).to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # Weighted BCE Loss if class_weight is provided\n",
    "        pos_weight = None\n",
    "        if class_weight == 'balanced':\n",
    "            n_neg = (y == 0).sum()\n",
    "            n_pos = (y == 1).sum()\n",
    "            pos_weight = torch.tensor(n_neg / n_pos, dtype=torch.float32).to(self.device)\n",
    "            \n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(X_tensor).squeeze()\n",
    "            loss = criterion(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = torch.sigmoid(self.model(X_tensor))\n",
    "        prob_pos = outputs.cpu().numpy().flatten()\n",
    "        return np.vstack([1 - prob_pos, prob_pos]).T\n",
    "\n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)[:, 1]\n",
    "        return (probs >= 0.5).astype(int)\n",
    "\n",
    "def run_baseline(df, label_col, use_gpu=True):\n",
    "    \n",
    "    # --- Patient-level split ---\n",
    "    patient_ids = df['id'].unique()\n",
    "    stratify_labels = df.groupby('id')[label_col].max()\n",
    "    \n",
    "    train_ids, test_ids = train_test_split(\n",
    "        patient_ids,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=stratify_labels\n",
    "    )\n",
    "    \n",
    "    train_df = df[df['id'].isin(train_ids)]\n",
    "    test_df = df[df['id'].isin(test_ids)]\n",
    "    \n",
    "    # --- Features ---\n",
    "    feature_cols = df.columns.drop(['id', 'sepsis', label_col])\n",
    "    \n",
    "    X_train = train_df[feature_cols]\n",
    "    y_train = train_df[label_col]\n",
    "    X_test = test_df[feature_cols]\n",
    "    y_test = test_df[label_col]\n",
    "    \n",
    "    print(f\"Training on {len(X_train)} samples...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- Model ---\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        print(\"Using GPU (PyTorch)...\")\n",
    "        model = PyTorchLogisticRegression(input_dim=X_train.shape[1], device='cuda')\n",
    "        model.fit(X_train, y_train, class_weight='balanced')\n",
    "    else:\n",
    "        print(\"Using CPU (sklearn)...\")\n",
    "        model = LogisticRegression(\n",
    "            max_iter=3000,\n",
    "            class_weight='balanced',\n",
    "            solver='saga',      # better for large datasets\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    print(f\"Training completed in {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "    # --- Predictions ---\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # --- Metrics ---\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_prob)\n",
    "    }\n"
]

with open(path, 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=1)

print("Notebook updated with PyTorch/CUDA support.")
